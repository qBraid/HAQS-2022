{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Kernel Estimator Challenge\n",
    "\n",
    "For the first leg of the QML challenge, you implemented a variational quantum classifier (VQC) to take on a supervised learning problem based on the work of [Havlicek et al. (2018)](https://arxiv.org/pdf/1804.11326.pdf). Now, you will build on that experience, and explore Havlicek et al.'s second proposed method of applying quantum-enhanced feature spaces to machine learning: the *quantum kernel estimator*. In this challenge continuation, you will construct a QML model that estimates a kernel function using a quantum computer and optimize a classical support vector machine (SVM). For this classification protocol, we will continue to restrict ourselves to the binary label case, with $C = \\left\\{+1, −1\\right\\}$.\n",
    "\n",
    "Compared to the VQC challenge, we are providing very little template code for this kernel estimator challenge. This is by design to enable teams to further differentiate their model, especially in the training phase. The [Havlicek et al. (2018)](https://arxiv.org/pdf/1804.11326.pdf) paper is your best resource, and the [Kernel-based training Pennylane tutorial](https://pennylane.ai/qml/demos/tutorial_kernel_based_training.html) may also be helpful. You are free to import and use any additional packages that you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qbraid jobs enable haqs  # enable quantum jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_NAME = \"template\"  # enter team name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize dataset\n",
    "\n",
    "As before, we are given data from a training set $T$ and a test set $S$ of a subset $\\Omega \\in \\rm {I\\!R}^n$. Both are assumed to be labelled by the map $m: T \\cup S \\rightarrow \\{+1, −1\\}$ unkown to the algorithm. To generate the data, two random vectors in the X-Z plane of the Bloch sphere are chosen. Around these two vectors, we randomly sample two sets of quantum data points; the task is to learn to distinguish the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run gen_binary.py  # uncomment to generate new train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "\n",
    "file = open(DATA_PATH + \"params.json\")\n",
    "\n",
    "params = json.load(file)\n",
    "delta = params[\"delta\"]\n",
    "n_points = params[\"n_points\"]\n",
    "\n",
    "file.close()\n",
    "\n",
    "# Load data\n",
    "Xs = np.zeros(shape=(n_points, 2))\n",
    "Ys = np.zeros(shape=(n_points,))\n",
    "\n",
    "with open(DATA_PATH + \"binary_data.csv\", mode=\"r\") as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    for i, row in enumerate(csvFile):\n",
    "        Xs[i] = np.array([float(row[0]), float(row[1])])\n",
    "        Ys[i] = float(row[2])\n",
    "        if i == n_points:\n",
    "            break\n",
    "\n",
    "n_sets = 2\n",
    "samples_per_set = 40\n",
    "n_samples = n_sets * samples_per_set\n",
    "X_data, Y_data = Xs[:n_samples], Ys[:n_samples]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_data, Y_data, train_size=1 / n_sets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_xs = lambda x: [[x[i][j] for i in range(len(x))] for j in [0, 1]]\n",
    "\n",
    "xi, xj = split_xs(Xs)\n",
    "xi_train, xj_train = split_xs(X_train)\n",
    "xi_test, xj_test = split_xs(X_test)\n",
    "\n",
    "label_circle = mlines.Line2D(\n",
    "    [],\n",
    "    [],\n",
    "    color=\"none\",\n",
    "    marker=\"o\",\n",
    "    markerfacecolor=\"none\",\n",
    "    markeredgecolor=\"black\",\n",
    "    label=f\"Train ({len(X_train)})\",\n",
    ")\n",
    "label_square = mlines.Line2D(\n",
    "    [],\n",
    "    [],\n",
    "    color=\"none\",\n",
    "    marker=\"s\",\n",
    "    markerfacecolor=\"none\",\n",
    "    markeredgecolor=\"black\",\n",
    "    label=f\"Test ({len(X_test)})\",\n",
    ")\n",
    "\n",
    "plt.scatter(xi, xj, marker=\"o\", c=[\"r\" if v == 1.0 else \"b\" for v in Ys])\n",
    "plt.scatter(xi_train, xj_train, c=[\"k\" if v == 1.0 else \"y\" for v in Y_train])\n",
    "plt.scatter(xi_test, xj_test, marker=\"s\", c=[\"k\" if v == 1.0 else \"y\" for v in Y_test])\n",
    "plt.xticks([0, 2 * np.pi], [r\"$0$\", r\"$2\\pi$\"])\n",
    "plt.yticks([0, 2 * np.pi], [r\"$0$\", r\"$2\\pi$\"])\n",
    "plt.xlabel(\"$\\\\theta$\")\n",
    "plt.ylabel(\"$\\phi$\")\n",
    "plt.legend(handles=[label_circle, label_square], loc=\"upper right\")\n",
    "plt.title(f\"Classification Data, $\\Delta = {delta}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An arbitrary single qubit state can be written:\n",
    "\n",
    "$$ \\left| \\psi \\right\\rangle = e^{i \\gamma} \\big(\\cos \\frac{\\theta}{2}\\left|0\\right\\rangle + e^{i \\phi} \\sin \\frac{\\theta}{2}\\left|1\\right\\rangle \\big) $$ \n",
    "\n",
    "where $\\theta$, $\\phi$ and $\\gamma$ are real numbers. The numbers $0 \\leq \\theta \\leq \\pi$ and $0 \\leq \\phi \\leq 2\\pi$ define a point on the Bloch sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable, mx):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    pset = chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))\n",
    "    return [l for l in list(pset) if len(l) == mx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(x):\n",
    "    \"\"\"Non-linear encoding (transformation) of one input data vector\n",
    "\n",
    "    Args:\n",
    "        x : shape (2,) tensor containing one input data vector\n",
    "\n",
    "    Returns:\n",
    "        triple of data encoded coefficients phi_1, phi_2, phi_{1,2}\n",
    "    \"\"\"\n",
    "\n",
    "    return x[0], x[1], (np.pi - x[0]) * (np.pi - x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering only Ising type interactions ($d=2$), the unitaries are generated from one- and two- big gates of the form\n",
    "\n",
    "$$U_{\\phi_{\\{k\\}}(\\textbf{x})} = \\exp\\big(i\\phi_{\\{k\\}}(\\textbf{x})Z_k \\big)$$\n",
    "$$U_{\\phi_{\\{l,m\\}}(\\textbf{x})} = \\exp\\big(i\\phi_{\\{k,l\\}}(\\textbf{x})Z_kZ_l\\big)$$\n",
    "\n",
    "where we have followed Havlíček et al. and chosen $\\phi_{\\{ i \\}} = x_i$ and $\\phi_{\\{ 1,2 \\}} = (\\pi - x_1)(\\pi - x_2)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wires = 2  # number of qubits\n",
    "S_size = 2  # number of interactions considered\n",
    "pset = powerset(range(n_wires), S_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(x):\n",
    "    \"\"\"The embedding ansatz\n",
    "\n",
    "    Args:\n",
    "        x : shape (3,) tensor containing one encoded data vector\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum kernel (ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_kernel = qml.device(\"default.qubit\", wires=n_wires)\n",
    "\n",
    "projector = np.zeros((2**n_wires, 2**n_wires))\n",
    "projector[0, 0] = 1\n",
    "\n",
    "\n",
    "@qml.qnode(dev_kernel)\n",
    "def kernel(x, z):\n",
    "    \"\"\"Compute quantum kernel element for two feature vectors.\n",
    "\n",
    "    Args:\n",
    "        x : shape (2,) tensor containing one input data vector\n",
    "        z : shape (2,) tensor containing one input data vector\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x_enc = encode_data(x)\n",
    "    z_enc = encode_data(z)\n",
    "\n",
    "    for _ in range(S_size):\n",
    "        for i in range(n_wires):\n",
    "            qml.Hadamard(wires=i)\n",
    "        embedding(x_enc)\n",
    "\n",
    "    for _ in range(S_size):\n",
    "        qml.adjoint(embedding)(z_enc)\n",
    "        for i in range(n_wires):\n",
    "            qml.Hadamard(wires=i)\n",
    "\n",
    "    return qml.expval(qml.Hermitian(projector, wires=range(n_wires)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_ideal(A, B):\n",
    "    \"\"\"Ideal kernel matrix for sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ideal kernel matrix containing the inner products of all\n",
    "# data points used for training, c.f. Havlicek Fig. 4.a (right)\n",
    "\n",
    "k_ideal = kernel_ideal(X_train, X_train)\n",
    "\n",
    "im = plt.imshow(k_ideal, extent=(0, samples_per_set, 0, samples_per_set))\n",
    "plt.colorbar(im)\n",
    "plt.xticks([0, samples_per_set])\n",
    "plt.yticks([0, samples_per_set])\n",
    "plt.title(\"$K$ (ideal)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum kernel estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it will be convenient to write $T = \\left\\{\\textbf{x}_1,...,\\textbf{x}_t\\right\\}$ with $t = \\left|T\\right|$; also let $y_i = m(\\textbf{x}_i)$ be the corresponding label. In this protocol you will use a quantum computer to estimate the $t \\times t$ kernel matrix $K(\\textbf{x}_i, \\textbf{x}_j) = \\left|\\langle\\Phi(\\textbf{x}_i)|\\Phi(\\textbf{x}_j)\\rangle\\right|^2$. For all pairs of points $\\textbf{x}_i, \\textbf{x}_j \\in T$ in the the training data, you will sample the overlap between feature states to obtain the matrix entry in the kernel. This fidelity can be estimated from the output probability of the circuit by sampling the output distribution with $R$ shots and only taking the $0^n$ count. The frequency of the $0^n$ count is an estimator of the Kernel entry up to an error $\\epsilon = O(R^{−1/2})$. After the kernel matrix for the full training data has been constructed we use the conventional (classical) support vector machine classifier. The optimal hyperplane can be found by solving the dual quadratic program $L_D$ for the variables $\\alpha = \\left\\{\\alpha_i\\right\\}_{i=1...t}$. Hence, to train, we maximize\n",
    "\n",
    "\\begin{equation}\n",
    "L_D(\\alpha) = \\sum_{i=1}^t \\alpha_i - \\frac{1}{2} \\sum_{i,j=1}^t y_i y_j \\alpha_i \\alpha_j K(\\textbf{x}_i, \\textbf{x}_j),\n",
    "\\label{eq:Ld} \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "subject to $\\sum_{i=1}^t \\alpha_i y_i = 0$ and $\\alpha_i \\geq 0$. This problem is concave, and therefore efficiently solvable, whenever $K(\\textbf{x}_i, \\textbf{x}_j)$ is a positive definite matrix. Standard quadratic programming solvers can be used. The solution to this problem will be given by a nonnegative vector $\\alpha^* = (\\alpha_1^*,...,\\alpha_t^*)$. Due to complementary slackness, we expect that many of the $\\alpha_i^*$ will be zero. Hence, there will only be subset of training samples that are needed to construct the optimal hyperplane. These samples are referred to as the support vectors.\n",
    "\n",
    "The training phase consists of the following steps:\n",
    "\n",
    "---\n",
    "### Algorithm 1: training\n",
    "1. **Input** Labeled training samples $T = \\left\\{ \\textbf{x} \\in \\Omega \\in {\\rm I\\!R}^n \\right\\} \\times \\left\\{ y \\in C \\right\\}$, quadratic program solver.\n",
    "2. **Parameters** Number of measurement shots $R$.\n",
    "3. Calibrate the quantum hardware to generate short depth circuits.\n",
    "4. **for** $\\textit{i} = 1$ to $\\textit{t}$ **do**\n",
    "5. $\\hspace{5mm}$ **for** $\\textit{j} = 1$ to $\\textit{t}$ **do**\n",
    "6. $\\hspace{10mm}$ Set the counter $r_{0^n} = 0$\n",
    "7. $\\hspace{10mm}$ **for** $\\textit{shot} = 1$ to $R$ **do**\n",
    "8. $\\hspace{15mm}$ Run the circuit from Havlicek Fig. 2.c. with paremeters $\\textbf{x}_i, \\textbf{x}_j$.\n",
    "9. $\\hspace{15mm}$ Measure outcome in $Z$-basis.\n",
    "10. $\\hspace{15mm}$ **if** Measurement outcome is $0^n$ **then**\n",
    "11. $\\hspace{20mm}$ Increase counter by one, setting $r_{0^n} \\rightarrow r_{0^n} + 1$.\n",
    "12. $\\hspace{15mm}$ **end if**\n",
    "13. $\\hspace{10mm}$ **end for**\n",
    "14. $\\hspace{10mm}$ Construct kernel estimate $\\hat{K}(\\textbf{x}_i, \\textbf{x}_j) = r_{0^n}R^{-1}$.\n",
    "15. $\\hspace{5mm}$ **end for**\n",
    "16. **end for**\n",
    "17. Use quadratic program solver to optimize $\\alpha$ in $L_D$ in eqn. (1) with kernel $K = \\hat{K}$ and set $T$.\n",
    "18. **return** the final parameters $\\alpha^*$ and value of the cost function $L_D$ and kernel estimator $\\hat{K}$.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = 1000\n",
    "\n",
    "dev_est = qml.device(\"default.qubit\", wires=n_wires, shots=shots)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_est)\n",
    "def fidelity_estimate(x, z):\n",
    "    \"\"\"Directly estimate the fidelity between a pair of feature vectors for data `x` and `z`\n",
    "\n",
    "    Args:\n",
    "        x : shape (2,) tensor containing one input data vector\n",
    "        z : shape (2,) tensor containing one input data vector\n",
    "\n",
    "    Returns:\n",
    "        shape (2, `R`) tensor containing `R` Z-basis measurement samples on each qubit, where `R` \n",
    "        is the number of shots determined from the dev.shots attribute of the corresponding device.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_experimental(A, B):\n",
    "    \"\"\"Experimentally estimated kernel matrix for sets A and B.\"\"\"\n",
    "\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize experimental kernel matrix containing the inner products of all\n",
    "# data points used for training, c.f. Havlicek Fig. 4.a (left)\n",
    "\n",
    "k_experimental = kernel_experimental(X_train, X_train)\n",
    "\n",
    "im = plt.imshow(k_experimental, extent=(0, samples_per_set, 0, samples_per_set))\n",
    "plt.colorbar(im)\n",
    "plt.xticks([0, samples_per_set])\n",
    "plt.yticks([0, samples_per_set])\n",
    "plt.title(\"$\\hat{K}$ (experimental)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement training algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classification phase, we want to assign a label to a new datum $s \\in S$ of the test set. For this, the inner products $K(\\textbf{x}_i, \\textbf{s})$ between all support vectors $\\textbf{x}_j \\in T$ with $\\alpha_i^* > 0$ and the new datum s have to be estimated on the quantum computer, c.f. Havlicek Fig. S5.b. The new label $\\tilde{m}(\\textbf{s})$ for the datum is assigned according to Havlicek eqn. (14). Since all support vectors are known from the training phase and we have obtained access to the kernel $K(\\textbf{x}_i,\\textbf{s})$ from the quantum hardware, the label can be directly computed according to\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{m}(\\textbf{s}) = \\text{sign} \\bigg(\\sum_{i=1}^t y_i \\alpha_i^* K(\\textbf{x}_i, \\textbf{s}) + b \\bigg).\n",
    "\\label{eq:ms} \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Note that the bias $b$ in $\\tilde{m}(\\textbf{s})$ can be calculated from the weights $\\alpha_i^*$ by choosing any $i$ with $\\alpha_i^* > 0$ and solving $\\sum_j y_j \\alpha_j^* K(\\textbf{x}_j, \\textbf{x}_i) + b = y_i$ for $b$.\n",
    "\n",
    "---\n",
    "### Algorithm 2: classification\n",
    "1. **Input** An unlabeled sample from the test set $\\textbf{s} \\in S$, optimal SVM parameters $\\alpha, b$ and training data set $T$. \n",
    "2. **Parameters** Number of measurement shots $R$.\n",
    "3. Calibrate the quantum hardware to generate short depth circuits.\n",
    "4. **for** $\\textit{i} = 1$ to $\\textit{t}$ with $\\alpha_i^* > 0$ **do**\n",
    "5. $\\hspace{5mm}$ Set the counter $r_{0^n} = 0$\n",
    "7. $\\hspace{5mm}$ **for** $\\textit{shot} = 1$ to $R$ **do**\n",
    "8. $\\hspace{10mm}$ Run the circuit from Havlicek Fig. 2.c. with paremeters $\\textbf{x}_i, \\textbf{s}$.\n",
    "9. $\\hspace{10mm}$ Measure outcome in $Z$-basis.\n",
    "10. $\\hspace{10mm}$ **if** Measurement outcome is $0^n$ **then**\n",
    "11. $\\hspace{15mm}$ Increase counter by one, setting $r_{0^n} \\rightarrow r_{0^n} + 1$.\n",
    "12. $\\hspace{10mm}$ **end if**\n",
    "13. $\\hspace{5mm}$ **end for**\n",
    "14. $\\hspace{5mm}$ Construct kernel estimate $\\hat{K}(\\textbf{x}_i, \\textbf{s}) = r_{0^n}R^{-1}$.\n",
    "15. **end for**\n",
    "16. **return** $\\text{sign}\\big(\\sum_{i=1}^t y_i \\alpha_i^* \\hat{K}(\\textbf{x}_i, \\textbf{s}) + b \\big)$.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
